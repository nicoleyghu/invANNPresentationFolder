{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summer 2019 CX4240 - Project\n",
    "\n",
    "Dr. Mahdi Roozbahani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Artificial Neural Network (ANN) ODE Solver\n",
    "\n",
    "### [**Project Proposal Document**](./proposal/proposal.pdf)\n",
    "\n",
    "### Group:\n",
    "\n",
    "   - Gabriel Sabenca Gusmao **[GSG]**\n",
    "   - Nicole Yuge Hu **[NYH]**\n",
    "   - Zhenzi Yu  **[ZY]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Issue\n",
    "\n",
    "**Inverse Problem: Model Selection and Parameter Fitting**\n",
    "\n",
    "   - Common problem in the field of chemical kinetics and reactors.\n",
    "   - Not well-posed, many parameters, needs regularization.\n",
    "   - Underlying differential equations may not be well understood.\n",
    "   - There may exist latent variables, e.g. adsorbate (intermediate chemical species) coverage fraction.\n",
    "\n",
    "   \n",
    " <div align=\"center\">\n",
    "    <b> Turnover Frequency (a, <i>f(state variables)</i>) and species coverage fractions (b, latent variables) from [1]</b>.\n",
    "</div>\n",
    "\n",
    "  <img src=\"./imgs/fig0.png\" alt=\"overview\" style=\"width: 625px;\"/> \n",
    "  \n",
    "  <div align=\"left\">[1] Gusm√£o, G. S. & Christopher, P. A general and robust approach for defining and solving microkinetic catalytic systems. AIChE J. (2015). doi:10.1002/aic.14627</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Proposal: Inverse ANN solution for ODE's for model selection and parameter regression.\n",
    "\n",
    "  - Although ANN structures might not be optimal for a given underlying model, it shall be flexible enough to handle stiffness.\n",
    "  - Potentially allows model inference.\n",
    "  - Parameters regression can be exact in the absence of latent variables.\n",
    "  - Regularization may allow parameter estimation in the presence of latent variables.\n",
    "  - Trade-offs between fitting the ANN scafold to data and fitting a proposed model to data should be explored.\n",
    "  \n",
    "#### 2.1 Forward Problem \n",
    "\n",
    "   The forward problem consists of solving the following minimization problem, where $\\theta_{i}$ is a general array of parameters of $i$. In the forward mode, the model and its parameters, $\\theta_{model}$ are known, and state variables $x(t)$ are solved for. $\\gamma$ generalizes the chosen norm.\n",
    "   \n",
    "   $$\\underset{\\theta_{ANN}}{\\min}\\|\\dot{x}(\\theta_{ANN} | t)-f(x|\\theta_{model}) \\|_{\\gamma}$$\n",
    "   \n",
    "   for $f(x)=\\dot{x}$ and $\\dot{x}$ can be estimated as of backprogapation (chain rule) through the ANN, in which case we shall use automatic differentiation.\n",
    "   \n",
    "#### 2.2 Inverse Problem\n",
    "\n",
    "   Now state variables $x(t)$ are given and neither the model nor its parameters are known.\n",
    "   \n",
    "   $$\\underset{\\theta_{ANN},\\theta_{model}}{\\min}\\alpha\\|\\tilde{x}(t)-x(\\theta_{ANN} | t) \\|_{\\gamma}+(1-\\alpha)\\|\\dot{x}(\\theta_{ANN} | t)-f(x|\\theta_{model}) \\|_{\\gamma}+\\mathcal{R}(\\theta_{model})$$\n",
    "   \n",
    "   $\\alpha$ can be atrbitrarily defined or evaluated in order to minimize the cost function. If $\\alpha\\to1$, the ANN accurately maps data from $t$ to $x$ but is not necessarily attached to the model; the opposite being true as $\\alpha\\to0$. $\\mathcal{R}(\\theta_{model})$ is a regularization term on model parameters to avoid derailing during the iterative minimization process.\n",
    "   \n",
    "   Regularization might not be necessary if cross-validation is used in the learning process.   \n",
    "      \n",
    "   <p></p>\n",
    "<div align=\"center\">\n",
    "<b> Project Diagram</b>.\n",
    "</div>\n",
    "\n",
    "  <img src=\"./imgs/fig1.png\" alt=\"overview\"/> \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Similar projects\n",
    "\n",
    "[**Neural Ordinary Differential Equations**](https://arxiv.org/abs/1806.07366v4) (https://arxiv.org/abs/1806.07366)   \n",
    "\n",
    "&ensp; [2] Chen, R. T. Q., Rubanova, Y., Bettencourt, J. & Duvenaud, D. Neural Ordinary Differential Equations. (2018).\n",
    "\n",
    "   - Extensive study on the forward problem automatic differentiation capability.\n",
    "   - Does not explore inverse problems.\n",
    "\n",
    "[**Hidden Physics Models: Machine Learning of Nonlinear Partial Differential Equations**](https://arxiv.org/abs/1708.00588) (https://arxiv.org/abs/1708.00588)   \n",
    "\n",
    "&ensp; [3] Raissi, M. & Karniadakis, G. E. Hidden Physics Models: Machine Learning of Nonlinear Partial Differential Equations. (2017).\n",
    "   \n",
    "   - Non-linear ordinary and partial differential equation identification.\n",
    "   - Uses Gaussian Processes as scaffold for learning.\n",
    "   - Assumes model is known apriori.\n",
    "   \n",
    "[**Solving coupled ODEs with a neural network and autograd**](http://kitchingroup.cheme.cmu.edu/blog/category/ode/ ) (Kitchin's Group)\n",
    "\n",
    "   - Solves the forward ODE for kinetic systems using ANN.\n",
    "   - Show example of automatic differentiation with *autograd*.\n",
    "   - Kitchin's work on the forward problem will be used as starting point for the inverse problem.\n",
    "   \n",
    "[**Multistep Neural Networks for Data-driven Discovery of Nonlinear Dynamical Systems**](https://arxiv.org/abs/1801.01236) (https://arxiv.org/abs/1801.01236)   \n",
    "\n",
    "\n",
    "&ensp; [4] Raissi, M., Perdikaris, P. & Karniadakis, G. E. Multistep Neural Networks for Data-driven Discovery of Nonlinear Dynamical Systems. (2018).\n",
    "\n",
    "   - Solves multiple kinds of PDE's using ANN.\n",
    "   - Explore different time-stepping formulas.\n",
    "   - Discusses whole of noise and regularization\n",
    "   - Does not entail parameter fitting.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Identified Problems\n",
    "\n",
    "      \n",
    "   - Number of latent variables (intermediate species concentration/fractional coverage) is typically unknown and may be large. We expect a minimal model can be learned though. *This is very typical to kinetic models; i.e. a large model is initially devised and only a few branches of it are active at specific thermodynamic conditioons.* \n",
    "   - No bijection (surjection) might lead to multiple sets of parameters being able to accurately represent data. *Regularization along with cross-validation in learning strategy might narrow the space of potential kinetic parameters*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Library Dependencies\n",
    "\n",
    "\n",
    "- Automatic differentiation: [**JAX**](https://github.com/google/jax) (https://github.com/google/jax)\n",
    "- Array-operation: [**numpy**](https://www.numpy.org/)\n",
    "- Solution for initial-value problems, IVPs (forward problem): [**dasslc2py**](https://github.com/asanet/dasslc2py) (https://github.com/asanet/dasslc2py) or [**scipy**](https://www.scipy.org/)\n",
    "- Non-linear minimization (optimization): [**scipy**](https://www.scipy.org/) ... for now.\n",
    "- Artificial Neural Networks (ANN): [**TensorFlow**](https://www.tensorflow.org/) (https://www.tensorflow.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
