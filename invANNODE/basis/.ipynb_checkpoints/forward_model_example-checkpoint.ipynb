{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Wed Jun 19 17:45:50 2019\n",
    "\n",
    "@author: ggusmao3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, jacobian, jacfwd, jacrev\n",
    "from jax import random\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.experimental import optimizers\n",
    "from jax.config import config\n",
    "config.update(\"jax_debug_nans\", True)\n",
    "config.update('jax_enable_x64', True)\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"### Hyperparameters\n",
    "Let's get a few bookkeeping items out of the way.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# A helper function to randomly initialize weights and biases\n",
    "# for a dense neural network layer\n",
    "def random_layer_params(m, n, key, scale=1e-2):\n",
    "    ##print(key)\n",
    "    w_key, b_key = random.split(key)\n",
    "    ##print(np.shape(w_key))\n",
    "    ##print(np.shape(b_key))\n",
    "    #raise(Exception)\n",
    "    return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n",
    "def init_network_params(sizes, key):\n",
    "    keys = random.split(key, len(sizes))\n",
    "    return [random_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def transfer_fun(x):\n",
    "    #return np.maximum(0, x)\n",
    "    #return np.nan_to_num(x / (1.0 + np.exp(-x)))\n",
    "    return x / (1.0 + np.exp(-x))\n",
    "    #return np.tanh(x)\n",
    "    #return 0.5*np.tanh(x) + 0.5*x / (1.0 + np.exp(-x))\n",
    "    #return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def state(params, t):\n",
    "    # per-example stateions\n",
    "    activations = t\n",
    "    for w, b in params[:-1]:\n",
    "        outputs = np.dot(w, activations) + b\n",
    "        activations = transfer_fun(outputs)\n",
    "    \n",
    "    final_w, final_b = params[-1]\n",
    "    y = (np.dot(final_w, activations) + final_b)**2\n",
    "    #y = y / y.sum()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a batched version of the `state` function\n",
    "batched_state = vmap(state, in_axes=(None,0))#, in_axes=(None, 0))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def accuracy(params, t, targets):\n",
    "   target_class = np.argm25ax(targets, axi25s=1)\n",
    "   stateed_class = np.argmax(batched_state(params, t), axis=1)\n",
    "   return np.mean(stateed_class == target_class)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def accuracy(params, t, target_x):\n",
    "   pred_x = batched_state(params,t)\n",
    "   y    = pred_x-np.mean(pred_x) \n",
    "   y_ = target_x-np.mean(target_x)\n",
    "   ##print(np.shape(y),np.shape(y_))\n",
    "   return np.mean(np.dot(y.T,y_)**2/(np.dot(y.T,y)*np.dot(y_.T,y_)))*np.exp(-np.mean((pred_x-target_x)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def diff_state(params,t):\n",
    "        i = np.arange(len(t))\n",
    "        return (jacobian(batched_state,argnums=1)(params,t)[i,:,i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def model(params_model,x):\n",
    "        #print('model x: {}'.format(x))\n",
    "        #x = np.abs(np.nan_to_num(x))\n",
    "        return np.array([[-params_model[0]*(x[0]**2)+params_model[3]*x[3]**2+params_model[3]*x[2]**2],\n",
    "                                         [params_model[0]*(x[0]**2) - params_model[1]*((x[1])**1.5)],\n",
    "                                         [params_model[1]*((x[1])**1.5)-params_model[3]*x[2]**2],\n",
    "                                         [params_model[2]*(x[1]*x[0])-params_model[3]*x[3]**2]])\n",
    "\n",
    "batched_model = vmap(model, in_axes=(None,0))#, in_axes=(None, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "params_model = np.array([1.,1.,0.5,.1])\n",
    "bc=np.array([1.0,0.,0.,0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def loss(params, t):\n",
    "    pred_x = (batched_state(params, t))\n",
    "    err = (((diff_state(params,t))-(batched_model(params_model,pred_x)[:,:,0]))**2).mean()\n",
    "    #print('pred[0]: {}'.format(pred_x[0]))\n",
    "    #print('sum pred[0] - bc: {}'.format(sum((pred_x[0]-bc)**2)))\n",
    "    return err+((pred_x[0]-bc)**2).mean()#+((pred_x.sum(axis=1)-1.)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#@jit\n",
    "#def update(params, t):\n",
    "#    grads = jacobian(loss,argnums=0)(params, t)\n",
    "#    #grads = [tuple(i.sum(axis=0) for i in j) for j in grads]\n",
    "#    return [(w - step_size * dw, b - step_size * db)\n",
    "#                    for (w, b), (dw, db) in zip(params, grads)]\n",
    "# Use optimizers to set optimizer initialization and update functions\n",
    "r=1\n",
    "layer_sizes = [1, 12, 4]\n",
    "param_scale = .1\n",
    "num_epochs = 1000\n",
    "num_eras = 20\n",
    "batch_size = 50\n",
    "params = init_network_params(layer_sizes, random.PRNGKey(0))\n",
    "\n",
    "opt_init, opt_update, get_params = optimizers.adam(1e-3,eps=1e-50)#sgd(1e-2)#(1e-2, gamma=0.9, eps=1e-6)#(1e-4)#, b1=0.01, b2=0.9, eps=1e-12)#, b1=0.1, b2=0.999, eps=1e-10)\n",
    "\n",
    "x = np.logspace(0,np.log10(51),300).reshape((-1,1))-1.\n",
    "\n",
    "@jit\n",
    "def step(i, opt_state, t):\n",
    "    params = get_params(opt_state)\n",
    "    grads = jacobian(loss,argnums=0)(params, t)    \n",
    "    return opt_update(i, grads, opt_state)\n",
    "\n",
    "couter = itertools.count()\n",
    "opt_state = opt_init(params)\n",
    "for j in range(int(num_eras)):\n",
    "        batch = np.concatenate((np.array([x[0]]),x[random.shuffle(random.PRNGKey(j),np.arange(len(x)))[:batch_size],:]))\n",
    "        for i in range(int(num_epochs)):\n",
    "            #print(i)\n",
    "            opt_state = step(next(couter), opt_state, batch)\n",
    "            #print('--.--')    \n",
    "params = get_params(opt_state)\n",
    "#print(np.shape(opt_state.packed_state[3][0]))\n",
    "batched_state(params,x),x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from scipy.integrate import solve_ivp\n",
    "def ode(t, C):\n",
    "        Ca, Cb, Cc, Cd = C\n",
    "        dCadt = -k1 * Ca**2 + k4*Cd**2 + k4*Cc**2\n",
    "        dCbdt = k1 * Ca**2 - k2 * Cb**1.5\n",
    "        dCcdt = k2 * Cb**1.5 - k4*Cc**2\n",
    "        dCddt = k3 * Ca * Cb - k4*Cd**2\n",
    "        return [dCadt, dCbdt, dCcdt, dCddt]\n",
    "\n",
    "C0 = [1.0, 0.0, 0.0, 0.0]\n",
    "k1 = 1\n",
    "k2 = 1\n",
    "k3 = 0.5\n",
    "k4 = .1\n",
    "sol = solve_ivp(ode, (0, 50), C0, t_eval = x.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#print((batched_state(params,x)).sum(axis=1))\n",
    "#print((sol.y).sum(axis=0))\n",
    "plt.plot(sol.t, sol.y.T)\n",
    "plt.plot(x.flatten(),batched_state(params,x),'-o',lw=0.2,ms=2)\n",
    "plt.legend(['A', 'B', 'C', 'D'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('C');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3",
   "formats": "ipynb,py:light",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
