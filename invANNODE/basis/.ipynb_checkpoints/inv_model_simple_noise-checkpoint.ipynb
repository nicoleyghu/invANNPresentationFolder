{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Wed Jun 19 17:45:50 2019\n",
    "\n",
    "@author: ggusmao3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "import jax.numpy as np\n",
    "from numpy.random import choice\n",
    "from jax import grad, jit, vmap, jacobian, jacfwd, jacrev\n",
    "from jax import random\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.experimental import optimizers\n",
    "from jax.config import config\n",
    "from jax.tree_util import tree_map\n",
    "config.update(\"jax_debug_nans\", True)\n",
    "config.update('jax_enable_x64', True)\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"### Hyperparameters\n",
    "Let's get a few bookkeeping items out of the way.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# A helper function to randomly initialize weights and biases\n",
    "# for a dense neural network layer\n",
    "def random_layer_params(m, n, key, scale=1e-2):\n",
    "    w_key, b_key = random.split(key)\n",
    "    return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to randomly initialize weights and biases\n",
    "# for a dense neural network layer\n",
    "def random_model_params(m, key, scale=1e-2):\n",
    "    #w_key, b_key = random.split(key)\n",
    "    #print(tuple(scale * random.normal(key, (m, 1))))\n",
    "    return (scale * random.normal(key, (m,)))#, scale * random.normal(b_key, (n,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n",
    "def init_network_params(sizes, key, scale):\n",
    "    keys = random.split(key, len(sizes))\n",
    "    return [random_layer_params(m, n, k, scale) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_params(size, key, scale):\n",
    " key = random.split(key,2)[-1] \n",
    " return random_model_params(size, key, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def transfer_fun(x):\n",
    "    #return np.maximum(0, x)\n",
    "    #return np.nan_to_num(x / (1.0 + np.exp(-x)))\n",
    "    #return x / (1.0 + np.exp(-x))\n",
    "    return np.tanh(x)\n",
    "    #return 0.5*np.tanh(x) + 0.5*x / (1.0 + np.exp(-x))\n",
    "    #return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def state(params, t):\n",
    "    # per-example stateions\n",
    "    activations = t\n",
    "    for w, b in params[:-1]:\n",
    "        outputs = np.dot(w, activations) + b\n",
    "        activations = transfer_fun(outputs)\n",
    "    \n",
    "    final_w, final_b = params[-1]\n",
    "    y = (np.dot(final_w, activations) + final_b)\n",
    "    #y = y / y.sum()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a batched version of the `state` function\n",
    "batched_state = vmap(state, in_axes=(None,0))#, in_axes=(None, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def diff_state(params,t):\n",
    "        i = np.arange(len(t))\n",
    "        return (jacobian(batched_state,argnums=1)(params,t)[i,:,i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def model(model_params,x):\n",
    "        #print('model x: {}'.format(x))\n",
    "        #x = np.abs(np.nan_to_num(x))\n",
    "        mp = model_params\n",
    "        return np.array([[-mp[0]*(x[0])],\n",
    "                                         [mp[0]*(x[0]) - mp[1]*((x[1]))],\n",
    "                                         [mp[1]*((x[1]))]])\n",
    "        \n",
    "        \"\"\"\n",
    "        return np.array([[-mp[0]*(x[0])],0\n",
    "                                         [mp[0]*(x[0]) - mp[1]*((x[1]))],\n",
    "                                         [mp[1]*((x[1]))]])\n",
    "        \"\"\"\n",
    "batched_model = vmap(model,in_axes=(None,0))#, in_axes=(None, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params0 = np.array([1.,2.])\n",
    "bc0=np.array([1.,0.,0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " %%time\n",
    "\n",
    "tmax = 6.\n",
    "t = np.logspace(0,np.log10(tmax+1),60).reshape((-1,1))-1.\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "def ode(t,C):\n",
    "        return model(model_params0,C).flatten()\n",
    "\n",
    "n_points = 100\n",
    "\n",
    "t_eval = np.logspace(0,np.log10(tmax),n_points)-1.\n",
    "#t_eval = np.linspace(0,tmax,n_points)\n",
    "sol = solve_ivp(ode, (0, tmax), bc0, t_eval = t_eval)\n",
    "\n",
    "plt.figure(figsize=[10,10*2./3])\n",
    "t = sol.t\n",
    "x0 = sol.y.T\n",
    "x = x0#+random.normal(random.PRNGKey(0),sol.y.T.shape)*0.025\n",
    "plt.plot(sol.t, x0)\n",
    "plt.plot(sol.t, x,'.-',ms=5,lw=0.5)\n",
    "#plt.legend(['A', 'B', 'C', 'D'])\n",
    "plt.legend(['A', 'B', 'C','D'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('C');\n",
    "\n",
    "t = t.reshape([-1,1])\n",
    "\n",
    "data = (x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def get_errors(nn_params,model_params,batch):\n",
    "    x, t = batch\n",
    "    pred_x = (batched_state(nn_params, t))\n",
    "    err_model = ((diff_state(nn_params,t)-batched_model(model_params,pred_x)[:,:,0]))**2\n",
    "    err_data    =    (x-pred_x)**2+(np.log(1.+np.abs(x))-np.log(1.+np.abs(pred_x)))**2#((x-pred_x)**2).sum(axis=0).mean()\n",
    "    return err_data, err_model        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def loss(nn_params, model_params, batch):\n",
    "    #print('pred[0]: {}'.format(pred_x[0]))\n",
    "    #print('sum pred[0] - bc: {}'.format(sum((pred_x[0]-bc)**2))) \n",
    "    err_data, err_model = get_errors(nn_params,model_params,batch)\n",
    "    return err_data.mean()+err_model.mean()#*(1.+err_data.var())+np.sum([-np.nan_to_num(np.log(-i)) for i in model_params])#((pred_x[0]-bc)**2).mean()#+((pred_x.sum(axis=1)-1.)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [1, 8, len(bc0)]\n",
    "model_size = len(model_params0)\n",
    "nn_scale = .01\n",
    "model_scale = .01\n",
    "num_epochs = 100\n",
    "num_eras = 100\n",
    "batch_size = n_points-1\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "#nn_params = init_network_params(layer_sizes, key, nn_scale)\n",
    "#model_params = init_model_params(model_size, key, model_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_init_nn, opt_update_nn, get_params_nn = optimizers.adam(1e-3, b1=0.9, b2=0.9999, eps=1e-100)#, b1=0.1, b2=0.999, eps=1e-10)\n",
    "opt_init_model, opt_update_model, get_params_model = optimizers.adam(1e-3, b1=0.9, b2=0.9999, eps=1e-100)\n",
    "    \n",
    "\n",
    "@jit\n",
    "def step_nn(i, opt_state_nn, opt_state_model, batch):\n",
    "    nn_params = get_params_nn(opt_state_nn)\n",
    "    model_params = get_params_model(opt_state_model)\n",
    "    grads_nn = grad(loss,argnums=0)(nn_params, model_params, batch)    \n",
    "    return opt_update_nn(i, grads_nn, opt_state_nn)\n",
    "\n",
    "\n",
    "@jit\n",
    "def step_model(i, opt_state_nn, opt_state_model, batch):\n",
    "    nn_params = get_params_nn(opt_state_nn)\n",
    "    model_params = get_params_model(opt_state_model)\n",
    "    grads_model = grad(loss,argnums=1)(nn_params, model_params, batch)    \n",
    "    return opt_update_model(i, grads_model, opt_state_model)\n",
    " \n",
    "itercount    = itertools.count()        \n",
    "\n",
    "opt_state_nn = opt_init_nn(nn_params)\n",
    "opt_state_model = opt_init_model(model_params)\n",
    "\n",
    "for j in range(num_eras):\n",
    "        #sel = random.shuffle(random.PRNGKey(j),np.arange(n_points))    \n",
    "        err_data, err_model = get_errors(nn_params,model_params,data)\n",
    "        err_dist = err_data.mean(axis=1)#+err_model.mean(axis=1)\n",
    "        err_dist = err_dist/err_dist.sum()     \n",
    "        sel = choice(np.arange(len(data[1])),batch_size,False,err_dist.flatten())\n",
    "        batch = tuple(_[sel[:batch_size],:] for _ in data)\n",
    "        batch = data\n",
    "        loss_it_batch0 = np.inf\n",
    "        loss_it_sample0 = np.inf\n",
    "        for i in range(int(num_epochs)):\n",
    "            nn_params = get_params_nn(opt_state_nn)\n",
    "            model_params = get_params_model(opt_state_model)\n",
    "            print('Iteration: {:4d}, Loss Batch: {:.7e}, Loss Data: {:.7e}'.format(i,loss_it_sample0,loss_it_batch0))\n",
    "            it = next(itercount)\n",
    "            opt_state_nn        = step_nn(it, opt_state_nn, opt_state_model, batch) \n",
    "            opt_state_model = step_model(it, opt_state_nn, opt_state_model, batch)\n",
    "            loss_it_sample = loss(nn_params, model_params, batch)    \n",
    "            loss_it_batch = loss(nn_params, model_params, data)\n",
    "            #if loss_it_batch < loss_it_batch0*1.1:\n",
    "            #            pass                        \n",
    "            #else:\n",
    "            #            pass\n",
    "            loss_it_sample0 = loss_it_sample\n",
    "            loss_it_batch0 = loss_it_batch    \n",
    "            clear_output(wait=True)\n",
    "            #print('--.--')                                \n",
    "nn_params = get_params_nn(opt_state_nn)\n",
    "model_params = get_params_model(opt_state_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#print((batched_state(nn_params,model_params,x)).sum(axis=1))\n",
    "#print((sol.y).sum(axis=0))\n",
    "def ode2(t,C):\n",
    "        return model(np.abs(model_params),C).flatten()\n",
    "\n",
    "sol2 = solve_ivp(ode2, (0, tmax), bc0, t_eval = t_eval)\n",
    "\n",
    "plt.figure(figsize=[10,10*2./3])\n",
    "plt.plot(t, x)\n",
    "plt.plot(t.flatten(),batched_state(nn_params, t),'-o',lw=0.2,ms=2)\n",
    "plt.plot(sol2.t, sol2.y.T,'-.',lw=0.75,ms=2)\n",
    "plt.legend(['A', 'B', 'C', 'D'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('C');\n",
    "\n",
    "display(dict(zip(model_params0,model_params)))\n",
    "plt.gca().set_xscale('log')\n",
    "plt.gca().set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice(np.arange(len(data[1])),batch_size,False,err_dist.flatten())\n",
    "\n",
    "        j += 1\n",
    "        sel = random.shuffle(random.PRNGKey(j),np.arange(n_points))    \n",
    "        err_data, err_model = get_errors(nn_params,model_params,data)\n",
    "        err_dist = err_data.mean(axis=1)#+err_model.mean(axis=1)\n",
    "        err_dist = err_dist/err_dist.sum()     \n",
    "        #sel = choice(np.arange(len(data[1])),batch_size,False,err_dist.flatten())\n",
    "        batch = tuple(_[sel[:batch_size],:] for _ in data)\n",
    "        #batch = data\n",
    "        loss_it_batch0 = np.inf\n",
    "        loss_it_sample0 = np.inf\n",
    "        for i in range(int(500)):\n",
    "            nn_params = get_params_nn(opt_state_nn)\n",
    "            model_params = get_params_model(opt_state_model)\n",
    "            print('Iteration: {:4d}, Loss Batch: {:.7e}, Loss Data: {:.7e}'.format(i,loss_it_sample0,loss_it_batch0))\n",
    "            it = next(itercount)\n",
    "            opt_state_nn        = step_nn(it, opt_state_nn, opt_state_model, batch) \n",
    "            opt_state_model = step_model(it, opt_state_nn, opt_state_model, batch)\n",
    "            loss_it_sample = loss(nn_params, model_params, batch)    \n",
    "            loss_it_batch = loss(nn_params, model_params, data)\n",
    "            #if loss_it_batch < loss_it_batch0*1.1:\n",
    "            #            pass                        \n",
    "            #else:\n",
    "            #            pass\n",
    "            loss_it_sample0 = loss_it_sample\n",
    "            loss_it_batch0 = loss_it_batch    \n",
    "            clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_data, err_model = get_errors(nn_params,model_params,data)\n",
    "\n",
    "        err_data, err_model = get_errors(nn_params,model_params,data)\n",
    "        err_dist = err_data.mean(axis=1)#+err_model.mean(axis=1)\n",
    "        err_dist = err_dist/err_dist.sum()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_data.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_model.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_dist"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3",
   "formats": "ipynb,py:light",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
