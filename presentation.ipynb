{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inverse Artificial Neural Network (ANN) ODE Solver\n",
    "\n",
    "### Summer 2019 CX4240 - Project\n",
    "\n",
    "Dr. Mahdi Roozbahani\n",
    "\n",
    "#### [**Project Proposal Document**](./proposal/proposal.pdf)\n",
    "\n",
    "### Group:\n",
    "\n",
    "   - Gabriel Sabenca Gusmao **[GSG]**\n",
    "   - Nicole Yuge Hu **[NYH]**\n",
    "   - Zhenzi Yu  **[ZY]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. Issue\n",
    "\n",
    "**a. ODEs in Chemical Engineering field: reactions**\n",
    "  - have traditional solver, which gives discrete value\n",
    "  - traditional solver cannot give continuous and transplatable result\n",
    "  - forward model: knowing parameters, want to get time dependent concentration curce\n",
    "<img src=\"./ODE.png\">  \n",
    "\n",
    "**b. Setting in this project**\n",
    "$$\\begin{eqnarray}\n",
    "A ⇌ & B & ⇌C \\\\ \n",
    "\\frac{dc_A}{dt}& = & -k_{1} A \\\\\n",
    "\\frac{dc_B}{dt}& = & k_1 A-k_2 B-k_{-1} B\\\\\n",
    "\\frac{dc_C}{dt}& = & k_2 B-k_{-2} C \\\\\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "**c. Inverse Problem: Model Selection and Parameter Fitting**\n",
    "\n",
    "   - Common problem in the field of chemical kinetics and reactors.\n",
    "   - Not well-posed, many parameters, needs regularization.\n",
    "   - Underlying differential equations may not be well understood.\n",
    "   - There may exist latent variables, e.g. adsorbate (intermediate chemical species) coverage fraction.\n",
    "\n",
    "   \n",
    " <div align=\"center\">\n",
    "    <b> Turnover Frequency (a, <i>f(state variables)</i>) and species coverage fractions (b, latent variables) from [1]</b>.\n",
    "</div>\n",
    "\n",
    "  <img src=\"./imgs/fig0.png\" alt=\"overview\" style=\"width: 625px;\"/> \n",
    "  \n",
    "  <div align=\"left\">[1] Gusmão, G. S. & Christopher, P. A general and robust approach for defining and solving microkinetic catalytic systems. AIChE J. (2015). doi:10.1002/aic.14627</div>\n",
    "  \n",
    "\n",
    "**d. Proposal**\n",
    "\n",
    "  - Although ANN structures might not be optimal for a given underlying model, it shall be flexible enough to handle stiffness.\n",
    "  - Potentially allows model inference.\n",
    "  - Parameters regression can be exact in the absence of latent variables.\n",
    "  - Regularization may allow parameter estimation in the presence of latent variables.\n",
    "  - Trade-offs between fitting the ANN scafold to data and fitting a proposed model to data should be explored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2. Model: Inverse ANN solution for ODE's for model selection and parameter regression.\n",
    "\n",
    " \n",
    "#### 2.1 Forward Problem \n",
    "\n",
    "   The forward problem consists of solving the following minimization problem, where $\\theta_{i}$ is a general array of parameters of $i$. In the forward mode, the model and its parameters, $\\theta_{model}$ are known, and state variables $x(t)$ are solved for. $\\gamma$ generalizes the chosen norm.\n",
    "   \n",
    "   $$\\underset{\\theta_{ANN}}{\\min}\\|\\dot{x}(\\theta_{ANN} | t)-f(x|\\theta_{model}) \\|_{\\gamma}$$\n",
    "   \n",
    "   for $f(x)=\\dot{x}$ and $\\dot{x}$ can be estimated as of backprogapation (chain rule) through the ANN, in which case we shall use automatic differentiation.\n",
    "   \n",
    "#### 2.2 Inverse Problem\n",
    "\n",
    "   Now state variables $x(t)$ are given and neither the model nor its parameters are known.\n",
    "   \n",
    "   $$\\underset{\\theta_{ANN},\\theta_{model}}{\\min}\\alpha\\|\\tilde{x}(t)-x(\\theta_{ANN} | t) \\|_{\\gamma}+(1-\\alpha)\\|\\dot{x}(\\theta_{ANN} | t)-f(x|\\theta_{model}) \\|_{\\gamma}+\\mathcal{R}(\\theta_{model})$$\n",
    "   \n",
    "   $\\alpha$ can be atrbitrarily defined or evaluated in order to minimize the cost function. If $\\alpha\\to1$, the ANN accurately maps data from $t$ to $x$ but is not necessarily attached to the model; the opposite being true as $\\alpha\\to0$. $\\mathcal{R}(\\theta_{model})$ is a regularization term on model parameters to avoid derailing during the iterative minimization process.\n",
    "   \n",
    "   Regularization might not be necessary if cross-validation is used in the learning process.   \n",
    "      \n",
    "   <p></p>\n",
    "<div align=\"center\">\n",
    "<b> Project Diagram</b>\n",
    "</div>\n",
    "  <img src=\"./imgs/fig1.png\" alt=\"overview\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. Result & Discussion\n",
    "\n",
    "\n",
    "**Forward problem**\n",
    "ANN ODE forward solution\n",
    "\n",
    "ANN ODE gradient\n",
    "\n",
    "**Inverse problem**\n",
    "ANN inverse solution\n",
    "\n",
    "ANN inverse gradient\n",
    "\n",
    "**Noisy data**\n",
    "\n",
    "**Latent variable exploration**\n",
    "\n",
    "\n",
    "Discussion\n",
    "\n",
    "- ANN has the advantages of being continuous, differentiable, closed-form solution in ANN meaning that it requires less memory, but at the same time, it requires more time to train on the dataset. \n",
    "- ANN can solve kinetics ODE in forward and inverse fashion. \n",
    "- ANN also works with noisy dataset that mimics actual experiment measurements. \n",
    "- ANN can also be used to extract model parameters and latent variables in inverse problem scheme. \n",
    "\n",
    "Future work: \n",
    "- Compatibility of ANN with stiff problems\n",
    "- Optimize discretization of domain like ivp_solver. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Forward problem: ANN ODE forward solution\n",
    "\n",
    "mapping from t to concentrations of three species\n",
    "\n",
    "Insert Image of forward problem, and gradient presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "ANN can handle forward solution of ODE with simple layer and nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inverse problem: ANN ODE inverse solution\n",
    "\n",
    "known state variables and try to predict model parameters. \n",
    "\n",
    "`autograd` package is used. \n",
    "\n",
    "Insert iamges of inverse problem, and gradient presentation. Comparison between predicted model parameters and real parameters for state variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ANN with noisy data\n",
    "\n",
    "to  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Similar projects\n",
    "\n",
    "[**Neural Ordinary Differential Equations**](https://arxiv.org/abs/1806.07366v4) (https://arxiv.org/abs/1806.07366)   \n",
    "\n",
    "&ensp; [2] Chen, R. T. Q., Rubanova, Y., Bettencourt, J. & Duvenaud, D. Neural Ordinary Differential Equations. (2018).\n",
    "\n",
    "   - Extensive study on the forward problem automatic differentiation capability.\n",
    "   - Does not explore inverse problems.\n",
    "\n",
    "[**Hidden Physics Models: Machine Learning of Nonlinear Partial Differential Equations**](https://arxiv.org/abs/1708.00588) (https://arxiv.org/abs/1708.00588)   \n",
    "\n",
    "&ensp; [3] Raissi, M. & Karniadakis, G. E. Hidden Physics Models: Machine Learning of Nonlinear Partial Differential Equations. (2017).\n",
    "   \n",
    "   - Non-linear ordinary and partial differential equation identification.\n",
    "   - Uses Gaussian Processes as scaffold for learning.\n",
    "   - Assumes model is known apriori.\n",
    "   \n",
    "[**Solving coupled ODEs with a neural network and autograd**](http://kitchingroup.cheme.cmu.edu/blog/category/ode/ ) (Kitchin's Group)\n",
    "\n",
    "   - Solves the forward ODE for kinetic systems using ANN.\n",
    "   - Show example of automatic differentiation with *autograd*.\n",
    "   - Kitchin's work on the forward problem will be used as starting point for the inverse problem.\n",
    "   \n",
    "[**Multistep Neural Networks for Data-driven Discovery of Nonlinear Dynamical Systems**](https://arxiv.org/abs/1801.01236) (https://arxiv.org/abs/1801.01236)   \n",
    "\n",
    "\n",
    "&ensp; [4] Raissi, M., Perdikaris, P. & Karniadakis, G. E. Multistep Neural Networks for Data-driven Discovery of Nonlinear Dynamical Systems. (2018).\n",
    "\n",
    "   - Solves multiple kinds of PDE's using ANN.\n",
    "   - Explore different time-stepping formulas.\n",
    "   - Discusses whole of noise and regularization\n",
    "   - Does not entail parameter fitting.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Identified Problems\n",
    "\n",
    "      \n",
    "   - Number of latent variables (intermediate species concentration/fractional coverage) is typically unknown and may be large. We expect a minimal model can be learned though. *This is very typical to kinetic models; i.e. a large model is initially devised and only a few branches of it are active at specific thermodynamic conditioons.* \n",
    "   - No bijection (surjection) might lead to multiple sets of parameters being able to accurately represent data. *Regularization along with cross-validation in learning strategy might narrow the space of potential kinetic parameters*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Library Dependencies\n",
    "\n",
    "\n",
    "- Automatic differentiation: [**JAX**](https://github.com/google/jax) (https://github.com/google/jax)\n",
    "- Array-operation: [**numpy**](https://www.numpy.org/)\n",
    "- Solution for initial-value problems, IVPs (forward problem): [**dasslc2py**](https://github.com/asanet/dasslc2py) (https://github.com/asanet/dasslc2py) or [**scipy**](https://www.scipy.org/)\n",
    "- Non-linear minimization (optimization): [**scipy**](https://www.scipy.org/) ... for now.\n",
    "- Artificial Neural Networks (ANN): [**TensorFlow**](https://www.tensorflow.org/) (https://www.tensorflow.org/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
